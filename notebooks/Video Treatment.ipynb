{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f998326b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import mediapipe as mp\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ad33d",
   "metadata": {},
   "source": [
    "# Notebook for video processing using mediapipe"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4759ae6",
   "metadata": {},
   "source": [
    "## Prototype for a single video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d94b04da",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mediapipe pose functions initialization\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4334ce6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load a video using cv2\n",
    "\n",
    "video_input = cv2.VideoCapture('testvideo/v_JumpingJack_g01_c01.avi')\n",
    "\n",
    "#Store the width and height for the video\n",
    "\n",
    "frame_width = int(video_input.get(3))\n",
    "frame_height = int(video_input.get(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32b436e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Extract parameters for the annotated video generation \n",
    "viddir, inputflnm = 'testvideo/', 'v_JumpingJack_g01_c01.avi'\n",
    "inflnm, inflext = inputflnm.split('.')\n",
    "ex_name =  inflnm.split('_')[1]\n",
    "\n",
    "!mkdir $inflnm\n",
    "\n",
    "outdir = inflnm + '/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b14845",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Graphic Results file names\n",
    "annotated_filename = f'{outdir}{inflnm}_annotated.{inflext}'\n",
    "black_filename = f'{outdir}{inflnm}_black.{inflext}'\n",
    "\n",
    "out_annotated = cv2.VideoWriter(annotated_filename, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "out_black = cv2.VideoWriter(black_filename, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da63ab75",
   "metadata": {},
   "outputs": [],
   "source": [
    "list_land = []\n",
    "with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "    i = 0\n",
    "    while video_input.isOpened():\n",
    "        ret, image = video_input.read()\n",
    "        if not ret:\n",
    "            break\n",
    "        \n",
    "        #Create black background\n",
    "        background = np.zeros((frame_height, frame_width, 3), np.uint8)\n",
    "            \n",
    "            \n",
    "        image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "        image.flags.writeable = False\n",
    "        results = pose.process(image)\n",
    "\n",
    "        image.flags.writeable = True\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "        \n",
    "        pose_landmarks = results.pose_landmarks\n",
    "        \n",
    "        pose_landmarks = np.array([[lmk.x * frame_width, lmk.y * frame_height, lmk.z * frame_width] for lmk in pose_landmarks.landmark], dtype=np.float32)\n",
    "        \n",
    "        list_land.append(pose_landmarks)\n",
    "        \n",
    "        mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "        mp_drawing.draw_landmarks(background, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "        \n",
    "        out_annotated.write(image)\n",
    "        out_black.write(background)\n",
    "        \n",
    "        frame_filename = f'{outdir}{inflnm}_frame{i}.jpg'\n",
    "        black_filename = f'{outdir}{inflnm}_black{i}.jpg'\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "        cv2.imwrite(black_filename, background)\n",
    "        cv2.imwrite(frame_filename, image)\n",
    "        \n",
    "video_input.release()\n",
    "out_annotated.release()\n",
    "out_black.release()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a86531c0",
   "metadata": {},
   "source": [
    "## Generalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41d540ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Mediapipe pose functions initialization\n",
    "mp_drawing = mp.solutions.drawing_utils\n",
    "mp_drawing_styles = mp.solutions.drawing_styles\n",
    "mp_pose = mp.solutions.pose"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d736a892",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create directories for storing the results\n",
    "!mkdir annotated_videos\n",
    "!mkdir black_videos\n",
    "!mkdir annotated_frames\n",
    "!mkdir black_frames\n",
    "!mkdir jsons"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87636247",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "#Iterate through the video files in directory, variables for the different outputs\n",
    "\n",
    "directory = 'testvideo/'\n",
    "ouput_annotated_videos = 'annotated_videos/'\n",
    "output_black_videos = 'black_videos/'\n",
    "output_annotated_frames = 'annotated_frames/'\n",
    "output_black_frames = 'black_frames/'\n",
    "\n",
    "#Initialize a dictionary to store landmark results for each frame\n",
    "landmark_dict = {}\n",
    "\n",
    "for filename in os.listdir(directory):\n",
    "    \n",
    "    if filename.startswith('.') == False: \n",
    "    \n",
    "        current_filepath = f'{directory}{filename}'\n",
    "\n",
    "        #Load a video using cv2\n",
    "        video_input = cv2.VideoCapture(current_filepath)\n",
    "\n",
    "        #Store the width and height for the current video\n",
    "        frame_width = int(video_input.get(3))\n",
    "        frame_height = int(video_input.get(4))\n",
    "\n",
    "        #Extract parameters for the data extraction\n",
    "        inflnm, inflext = filename.split('.')\n",
    "        exercise_name =  inflnm.split('_')[1]\n",
    "\n",
    "        #Current video filepath\n",
    "        current_filepath = f'{directory}/{filename}'\n",
    "\n",
    "        #Load a video using cv2\n",
    "        video_input = cv2.VideoCapture(current_filepath)\n",
    "\n",
    "        #Store the width and height for the current video\n",
    "        frame_width = int(video_input.get(3))\n",
    "        frame_height = int(video_input.get(4))\n",
    "\n",
    "        #Extract parameters for the data extraction\n",
    "        inflnm, inflext = filename.split('.')\n",
    "        ex_name =  inflnm.split('_')[1]\n",
    "\n",
    "        #Video outputs filepaths\n",
    "        annotated_filename = f'{ouput_annotated_videos}{inflnm}_annotated.{inflext}'\n",
    "        black_filename = f'{output_black_videos}{inflnm}_black.{inflext}'\n",
    "\n",
    "        #Initializing output videos\n",
    "        out_annotated = cv2.VideoWriter(annotated_filename, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "        out_black = cv2.VideoWriter(black_filename, cv2.VideoWriter_fourcc('M','J','P','G'), 10, (frame_width,frame_height))\n",
    "\n",
    "        with mp_pose.Pose(min_detection_confidence=0.5, min_tracking_confidence=0.5) as pose:\n",
    "\n",
    "            i = 0\n",
    "\n",
    "            #Iterates through each frame in the current video\n",
    "            while video_input.isOpened():\n",
    "                \n",
    "                ret, image = video_input.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "\n",
    "                #Create black background\n",
    "                background = np.zeros((frame_height, frame_width, 3), np.uint8)\n",
    "\n",
    "                #Create an image of the current frmae\n",
    "                image = cv2.cvtColor(cv2.flip(image, 1), cv2.COLOR_BGR2RGB)\n",
    "                image.flags.writeable = False\n",
    "                results = pose.process(image)\n",
    "                image.flags.writeable = True\n",
    "                image = cv2.cvtColor(image, cv2.COLOR_RGB2BGR)\n",
    "\n",
    "                #Stores the landmarks of the current frame\n",
    "                pose_landmarks = results.pose_landmarks\n",
    "                \n",
    "                frame_dict = {}\n",
    "                j = 0\n",
    "                for lmk in pose_landmarks.landmark:\n",
    "                    frame_dict[j] = [lmk.x * frame_width, lmk.y * frame_height, lmk.z * frame_width]\n",
    "                    j += 1\n",
    "                \n",
    "                landmark_dict[i] = frame_dict\n",
    "                \n",
    "                # Draws the landmarks in the two output videos\n",
    "                mp_drawing.draw_landmarks(image, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "                mp_drawing.draw_landmarks(background, results.pose_landmarks, mp_pose.POSE_CONNECTIONS, landmark_drawing_spec=mp_drawing_styles.get_default_pose_landmarks_style())\n",
    "\n",
    "                out_annotated.write(image)\n",
    "                out_black.write(background)\n",
    "\n",
    "                frame_filename = f'{output_annotated_frames}{inflnm}_frame{i}.jpg'\n",
    "                black_frame_filename = f'{output_black_frames}{inflnm}_black{i}.jpg'\n",
    "\n",
    "                i += 1\n",
    "\n",
    "                cv2.imwrite(black_frame_filename, background)\n",
    "                cv2.imwrite(frame_filename, image)\n",
    "\n",
    "        video_input.release()\n",
    "        out_annotated.release()\n",
    "        out_black.release()\n",
    "        \n",
    "        #Creates json file with video landmarks\n",
    "        with open(f'jsons/{inflnm}.json', 'w') as fp:\n",
    "            json.dump(landmark_dict, fp)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0fb3187",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
